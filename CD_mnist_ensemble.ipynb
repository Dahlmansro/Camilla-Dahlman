{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e43d6f",
   "metadata": {},
   "source": [
    "# MNIST - Ensemble Learning\n",
    "In this code exercise we are going to practice on creating different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a138b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1462e4",
   "metadata": {},
   "source": [
    "# Data\n",
    "Load the MNIST data and split it into a training set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for validation, and 10,000 for testing).You can use the code below: \n",
    "\n",
    "```python\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=10000, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=10000, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a314e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=10000, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fad06ad",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "Instantiate a (1) Random Forest, (2) ExtraTree and (3) LinearSVC model. You can use this code:\n",
    "```python\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "extra_trees_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = LinearSVC(max_iter=100, tol=20, random_state=42)\n",
    "```\n",
    "Train the models on the training data and print out the score for each model on the validation data (what does the score method do?). Example on using the score method:\n",
    "\n",
    "```python\n",
    "my_model_name.score(X_val, y_val)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a30b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Random Forest Done!\n",
      "Training Extra Trees...\n",
      "Extra Trees Done!\n",
      "Training Linear SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CD\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM Done!\n"
     ]
    }
   ],
   "source": [
    "#Jag hade problem med att köra fit så därav nedanstående kod\n",
    "print(\"Training Random Forest...\")\n",
    "random_forest_clf.fit(X_train, y_train)\n",
    "print(\"Random Forest Done!\")\n",
    "\n",
    "print(\"Training Extra Trees...\")\n",
    "extra_trees_clf.fit(X_train, y_train)\n",
    "print(\"Extra Trees Done!\")\n",
    "\n",
    "print(\"Training Linear SVM...\")\n",
    "svm_clf.fit(X_train, y_train)\n",
    "print(\"Linear SVM Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79c08e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 0.9692\n",
      "Extra Trees accuracy: 0.9715\n",
      "Linear SVM accuracy: 0.8590\n"
     ]
    }
   ],
   "source": [
    "rf_score = random_forest_clf.score(X_val, y_val)\n",
    "et_score = extra_trees_clf.score(X_val, y_val)\n",
    "svm_score = svm_clf.score(X_val, y_val)\n",
    "\n",
    "print(f\"Random Forest accuracy: {rf_score:.4f}\")\n",
    "print(f\"Extra Trees accuracy: {et_score:.4f}\")\n",
    "print(f\"Linear SVM accuracy: {svm_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de48cb9d",
   "metadata": {},
   "source": [
    "**Voting classifier**\n",
    "\n",
    "Create a voting classifier, train it on the training data and evaluate it on the validation data using the score method. \n",
    "Some code to help: \n",
    "\n",
    "```python\n",
    "named_estimators = [\n",
    "    (\"random_forest_clf\", random_forest_clf),\n",
    "    (\"extra_trees_clf\", extra_trees_clf),\n",
    "    (\"svm_clf\", svm_clf)\n",
    "]\n",
    "\n",
    "voting_clf = VotingClassifier(named_estimators)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5606dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Lista över de individuella modellerna med sina namn\n",
    "named_estimators = [\n",
    "    (\"random_forest_clf\", random_forest_clf),\n",
    "    (\"extra_trees_clf\", extra_trees_clf),\n",
    "    (\"svm_clf\", svm_clf)\n",
    "]\n",
    "\n",
    "# Skapa en Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=named_estimators, voting='hard')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2ea2955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Voting Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CD\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Voting Classifier...\")\n",
    "voting_clf.fit(X_train, y_train)\n",
    "print(\"Voting Classifier Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94c22e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier accuracy: 0.9693\n"
     ]
    }
   ],
   "source": [
    "#Börjar med att utvärdera på valideringsdatan\n",
    "voting_score = voting_clf.score(X_val, y_val)\n",
    "print(f\"Voting Classifier accuracy: {voting_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93756015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 0.9692\n",
      "Extra Trees accuracy: 0.9715\n",
      "Linear SVM accuracy: 0.8590\n",
      "Voting Classifier accuracy: 0.9693\n"
     ]
    }
   ],
   "source": [
    "#Sammanställer resultatetn för att lättare jämföra\n",
    "rf_score = random_forest_clf.score(X_val, y_val)\n",
    "et_score = extra_trees_clf.score(X_val, y_val)\n",
    "svm_score = svm_clf.score(X_val, y_val)\n",
    "voting_score = voting_clf.score(X_val, y_val)\n",
    "\n",
    "print(f\"Random Forest accuracy: {rf_score:.4f}\")\n",
    "print(f\"Extra Trees accuracy: {et_score:.4f}\")\n",
    "print(f\"Linear SVM accuracy: {svm_score:.4f}\")\n",
    "print(f\"Voting Classifier accuracy: {voting_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccfdbfa",
   "metadata": {},
   "source": [
    "# Evaluate your best model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cbbc723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: ExtraTreesClassifier\n",
      "Test set accuracy: 0.9691\n"
     ]
    }
   ],
   "source": [
    "best_model = extra_trees_clf  # Eftersom Extra Trees hade bäst valideringsaccuracy\n",
    "\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(f\"Best model: {best_model.__class__.__name__}\")\n",
    "print(f\"Test set accuracy: {test_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c29e46",
   "metadata": {},
   "source": [
    "# Summary and analysis\n",
    "In this section, write down a summary of your work and some analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e589679b",
   "metadata": {},
   "source": [
    "I teorin ska ensemble learning ge bättre prestanda, men här ser vi att Voting Classifier inte slog Extra Trees.\n",
    "\n",
    "Möjliga orsaker:\n",
    "\n",
    "Extra Trees var redan väldigt starkt\n",
    "\n",
    "Eftersom Extra Trees hade högst accuracy, kan det ha dominerat röstningen.\n",
    "Om en enskild modell är bäst, kan en ensemble ibland sänka prestandan.\n",
    "Linear SVM presterade dåligt\n",
    "\n",
    "85.90% accuracy är betydligt sämre än de andra två.\n",
    "Om SVM ofta gissar fel kan det ha påverkat Voting Classifier negativt.\n",
    "Majoritetsröstning fungerar inte alltid optimalt\n",
    "\n",
    "Eftersom vi använde hard voting (majoritetsröstning) kan det ha gjort att den starkaste modellen (Extra Trees) förlorade sin precision på grund av att de andra modellerna var svagare.\n",
    "\n",
    "Man skulle kunna testa Soft voting eller ta bort den svagaste modellen (Linear SVM)\n",
    "\n",
    "Vi ser också att modellen INTE överanpassar sig och att den generaliserar bra på ny data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96d253",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "548ceaea",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
